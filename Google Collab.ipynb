{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxA-Gx9mpCmU",
        "outputId": "2df5eebd-e7e0-4b52-cbf6-d13187ff01f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your GitHub token: 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\n",
            "Scraped 326 users and 39374 repositories\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import logging\n",
        "from typing import List, Dict\n",
        "\n",
        "class GitHubScraper:\n",
        "    def __init__(self, token: str):\n",
        "        \"\"\"\n",
        "        Initialize the GitHub scraper with your API token.\n",
        "\n",
        "        Args:\n",
        "            token (str): GitHub Personal Access Token\n",
        "        \"\"\"\n",
        "        self.headers = {\n",
        "            'Authorization': f'token {token}',\n",
        "            'Accept': 'application/vnd.github.v3+json'\n",
        "        }\n",
        "        self.base_url = 'https://api.github.com'\n",
        "\n",
        "        # Setup logging\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def _make_request(self, url: str, params: dict = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Make a request to the GitHub API with rate limit handling.\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            response = requests.get(url, headers=self.headers, params=params)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 403:\n",
        "                reset_time = int(response.headers.get('X-RateLimit-Reset', 0))\n",
        "                sleep_time = max(reset_time - time.time(), 0) + 1\n",
        "                self.logger.warning(f\"Rate limit hit. Sleeping for {sleep_time} seconds\")\n",
        "                time.sleep(sleep_time)\n",
        "            else:\n",
        "                self.logger.error(f\"Error {response.status_code}: {response.text}\")\n",
        "                response.raise_for_status()\n",
        "\n",
        "    def clean_company_name(self, company: str) -> str:\n",
        "        \"\"\"\n",
        "        Clean up company names according to specifications.\n",
        "        \"\"\"\n",
        "        if not company:\n",
        "            return \"\"\n",
        "\n",
        "        # Strip whitespace and @ symbol\n",
        "        cleaned = company.strip().lstrip('@')\n",
        "\n",
        "        # Convert to uppercase\n",
        "        return cleaned.upper()\n",
        "\n",
        "    def search_users(self, location: str, min_followers: int) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Search for GitHub users in a specific location with minimum followers.\n",
        "        \"\"\"\n",
        "        users = []\n",
        "        page = 1\n",
        "\n",
        "        while True:\n",
        "            self.logger.info(f\"Fetching users page {page}\")\n",
        "\n",
        "            query = f\"location:{location} followers:>={min_followers}\"\n",
        "            params = {\n",
        "                'q': query,\n",
        "                'per_page': 100,\n",
        "                'page': page\n",
        "            }\n",
        "\n",
        "            url = f\"{self.base_url}/search/users\"\n",
        "            response = self._make_request(url, params)\n",
        "\n",
        "            if not response['items']:\n",
        "                break\n",
        "\n",
        "            for user in response['items']:\n",
        "                user_data = self._make_request(user['url'])\n",
        "\n",
        "                # Extract only the required fields with exact matching names\n",
        "                cleaned_data = {\n",
        "                    'login': user_data['login'],\n",
        "                    'name': user_data['name'] if user_data['name'] else \"\",\n",
        "                    'company': self.clean_company_name(user_data.get('company')),\n",
        "                    'location': user_data['location'] if user_data['location'] else \"\",\n",
        "                    'email': user_data['email'] if user_data['email'] else \"\",\n",
        "                    'hireable': str(user_data['hireable']).lower() if user_data['hireable'] is not None else \"false\",\n",
        "                    'bio': user_data['bio'] if user_data['bio'] else \"\",\n",
        "                    'public_repos': user_data['public_repos'],\n",
        "                    'followers': user_data['followers'],\n",
        "                    'following': user_data['following'],\n",
        "                    'created_at': user_data['created_at']\n",
        "                }\n",
        "\n",
        "                users.append(cleaned_data)\n",
        "\n",
        "            page += 1\n",
        "\n",
        "        return users\n",
        "\n",
        "    def get_user_repositories(self, username: str, max_repos: int = 500) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Get repositories for a specific user.\n",
        "        \"\"\"\n",
        "        repos = []\n",
        "        page = 1\n",
        "\n",
        "        while len(repos) < max_repos:\n",
        "            self.logger.info(f\"Fetching repositories for {username}, page {page}\")\n",
        "\n",
        "            params = {\n",
        "                'sort': 'pushed',\n",
        "                'direction': 'desc',\n",
        "                'per_page': 100,\n",
        "                'page': page\n",
        "            }\n",
        "\n",
        "            url = f\"{self.base_url}/users/{username}/repos\"\n",
        "            response = self._make_request(url, params)\n",
        "\n",
        "            if not response:\n",
        "                break\n",
        "\n",
        "            for repo in response:\n",
        "                # Extract only the required fields with exact matching names\n",
        "                repo_data = {\n",
        "                    'login': username,  # Adding owner's login as required\n",
        "                    'full_name': repo['full_name'],\n",
        "                    'created_at': repo['created_at'],\n",
        "                    'stargazers_count': repo['stargazers_count'],\n",
        "                    'watchers_count': repo['watchers_count'],\n",
        "                    'language': repo['language'] if repo['language'] else \"\",\n",
        "                    'has_projects': repo['has_projects'],\n",
        "                    'has_wiki': repo['has_wiki'],\n",
        "                    'license_name': repo['license']['key'] if repo.get('license') else \"\"\n",
        "                }\n",
        "\n",
        "                repos.append(repo_data)\n",
        "\n",
        "            if len(response) < 100:\n",
        "                break\n",
        "\n",
        "            page += 1\n",
        "\n",
        "        return repos[:max_repos]\n",
        "\n",
        "def main():\n",
        "    # Get GitHub token\n",
        "    token = input(\"Enter your GitHub token: \").strip()\n",
        "    if not token:\n",
        "        print(\"Token is required. Exiting...\")\n",
        "        return\n",
        "\n",
        "    # Initialize scraper\n",
        "    scraper = GitHubScraper(token)\n",
        "\n",
        "    # Search for users in London with >500 followers\n",
        "    users = scraper.search_users(location='London', min_followers=500)\n",
        "\n",
        "    # Save users to CSV\n",
        "    users_df = pd.DataFrame(users)\n",
        "    users_df.to_csv('users.csv', index=False)\n",
        "\n",
        "    # Get repositories for each user\n",
        "    all_repos = []\n",
        "    for user in users:\n",
        "        repos = scraper.get_user_repositories(user['login'])\n",
        "        all_repos.extend(repos)\n",
        "\n",
        "    # Save repositories to CSV\n",
        "    repos_df = pd.DataFrame(all_repos)\n",
        "    repos_df.to_csv('repositories.csv', index=False)\n",
        "\n",
        "    print(f\"Scraped {len(users)} users and {len(all_repos)} repositories\")\n",
        "\n",
        "    # Create README.md\n",
        "    with open('README.md', 'w') as f:\n",
        "        f.write(f\"\"\"# GitHub Users in London\n",
        "\n",
        "This repository contains data about GitHub users in London with over 500 followers and their repositories.\n",
        "\n",
        "## Files\n",
        "\n",
        "1. `users.csv`: Contains information about {len(users)} GitHub users in London with over 500 followers\n",
        "2. `repositories.csv`: Contains information about {len(all_repos)} public repositories from these users\n",
        "3. `gitscrap.py`: Python script used to collect this data\n",
        "\n",
        "## Data Collection\n",
        "\n",
        "- Data collected using GitHub API\n",
        "- Date of collection: {time.strftime('%Y-%m-%d')}\n",
        "- Only included users with 500+ followers\n",
        "- Up to 500 most recently pushed repositories per user\n",
        "\"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file\n",
        "repos_df = pd.read_csv('repositories.csv')  # Adjust the path if necessary\n",
        "\n",
        "# Check the first few rows to ensure it's loaded correctly\n",
        "print(repos_df.head())\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to integers (1 for True, 0 for False)\n",
        "repos_df['has_projects'] = repos_df['has_projects'].astype(int)  # Convert True/False to 1/0\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].astype(int)          # Convert True/False to 1/0\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki\n",
        "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
        "\n",
        "# Round the correlation to 3 decimal places\n",
        "correlation_rounded = round(correlation, 3)\n",
        "\n",
        "print(\"Correlation between projects enabled and wiki enabled:\", correlation_rounded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLqsH1aZXUxQ",
        "outputId": "a04373e3-ed7a-4f5d-fec3-d8d6363c4800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  login                 full_name            created_at  stargazers_count  \\\n",
            "0    tj  tj/node-cookie-signature  2012-10-15T15:54:33Z               185   \n",
            "1    tj           tj/commander.js  2011-08-14T21:33:58Z             26742   \n",
            "2    tj                      tj/n  2011-01-05T14:53:19Z             18863   \n",
            "3    tj             tj/git-extras  2010-08-04T16:32:07Z             17327   \n",
            "4    tj           tj/node-migrate  2011-04-24T21:00:22Z              1545   \n",
            "\n",
            "   watchers_count    language  has_projects  has_wiki license_name  \n",
            "0             185  JavaScript          True      True          mit  \n",
            "1           26742  JavaScript          True      True          mit  \n",
            "2           18863       Shell          True      True          mit  \n",
            "3           17327       Shell          True      True          mit  \n",
            "4            1545  JavaScript          True      True          mit  \n",
            "Correlation between projects enabled and wiki enabled: 0.446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file\n",
        "repos_df = pd.read_csv('repositories.csv')  # Adjust the path if necessary\n",
        "\n",
        "# Check the first few rows to ensure it's loaded correctly\n",
        "print(repos_df.head())\n",
        "\n",
        "# Fill blank (NaN) values with 0 in 'has_projects' and 'has_wiki'\n",
        "repos_df['has_projects'] = repos_df['has_projects'].fillna(0)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].fillna(0)\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to integers (1 for True, 0 for False)\n",
        "repos_df['has_projects'] = repos_df['has_projects'].astype(int)  # Convert True/False to 1/0\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].astype(int)          # Convert True/False to 1/0\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki\n",
        "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
        "\n",
        "# Round the correlation to 3 decimal places\n",
        "correlation_rounded = round(correlation, 3)\n",
        "\n",
        "print(\"Correlation between projects enabled and wiki enabled:\", correlation_rounded)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EluvxTYJmZ8i",
        "outputId": "b05b378b-adee-4f2a-cf76-063db651aa5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  login                 full_name            created_at  stargazers_count  \\\n",
            "0    tj  tj/node-cookie-signature  2012-10-15T15:54:33Z               185   \n",
            "1    tj           tj/commander.js  2011-08-14T21:33:58Z             26742   \n",
            "2    tj                      tj/n  2011-01-05T14:53:19Z             18863   \n",
            "3    tj             tj/git-extras  2010-08-04T16:32:07Z             17327   \n",
            "4    tj           tj/node-migrate  2011-04-24T21:00:22Z              1545   \n",
            "\n",
            "   watchers_count    language  has_projects  has_wiki license_name  \n",
            "0             185  JavaScript          True      True          mit  \n",
            "1           26742  JavaScript          True      True          mit  \n",
            "2           18863       Shell          True      True          mit  \n",
            "3           17327       Shell          True      True          mit  \n",
            "4            1545  JavaScript          True      True          mit  \n",
            "Correlation between projects enabled and wiki enabled: 0.446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file\n",
        "repos_df = pd.read_csv('repositories.csv')  # Adjust the path if necessary\n",
        "\n",
        "# Check the first few rows to ensure it's loaded correctly\n",
        "print(repos_df.head())\n",
        "\n",
        "# Fill NaN values in the entire DataFrame with 0\n",
        "repos_df.fillna(0, inplace=True)\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to integers (1 for True, 0 for False)\n",
        "repos_df['has_projects'] = repos_df['has_projects'].astype(int)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].astype(int)\n",
        "\n",
        "# Create a Pearson correlation table for the entire DataFrame\n",
        "correlation_matrix = repos_df.corr(method='pearson')\n",
        "\n",
        "# Display the correlation matrix\n",
        "print(\"Pearson Correlation Matrix:\\n\", correlation_matrix)\n",
        "\n",
        "# Extract the correlation between 'has_projects' and 'has_wiki'\n",
        "correlation_projects_wiki = correlation_matrix.loc['has_projects', 'has_wiki']\n",
        "\n",
        "# Round the correlation to 3 decimal places\n",
        "correlation_projects_wiki_rounded = round(correlation_projects_wiki, 3)\n",
        "\n",
        "print(\"Correlation between projects enabled and wiki enabled:\", correlation_projects_wiki_rounded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "9nBI2sjQmoxx",
        "outputId": "2fa6fda0-1ca1-4313-8cb3-8c43e6df0f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  login                 full_name            created_at  stargazers_count  \\\n",
            "0    tj  tj/node-cookie-signature  2012-10-15T15:54:33Z               185   \n",
            "1    tj           tj/commander.js  2011-08-14T21:33:58Z             26742   \n",
            "2    tj                      tj/n  2011-01-05T14:53:19Z             18863   \n",
            "3    tj             tj/git-extras  2010-08-04T16:32:07Z             17327   \n",
            "4    tj           tj/node-migrate  2011-04-24T21:00:22Z              1545   \n",
            "\n",
            "   watchers_count    language  has_projects  has_wiki license_name  \n",
            "0             185  JavaScript          True      True          mit  \n",
            "1           26742  JavaScript          True      True          mit  \n",
            "2           18863       Shell          True      True          mit  \n",
            "3           17327       Shell          True      True          mit  \n",
            "4            1545  JavaScript          True      True          mit  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'tj'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-46b53c2a9a80>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Create a Pearson correlation table for the entire DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcorrelation_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pearson'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Display the correlation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mcorr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11047\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11048\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11049\u001b[0;31m         \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pearson\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mas_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1692\u001b[0m                 \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m             \u001b[0;31m# The underlying data was copied within _interleave, so no need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m             \u001b[0;31m# to further copy if copy=True or setting na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'tj'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file\n",
        "repos_df = pd.read_csv('repositories.csv')  # Adjust the path if necessary\n",
        "\n",
        "# Check the first few rows to ensure it's loaded correctly\n",
        "print(repos_df.head())\n",
        "\n",
        "# Fill NaN values in the entire DataFrame with 0\n",
        "repos_df.fillna(0, inplace=True)\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to integers (1 for True, 0 for False)\n",
        "repos_df['has_projects'] = repos_df['has_projects'].replace({True: 1, False: 0, 'True': 1, 'False': 0, '': 0})\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].replace({True: 1, False: 0, 'True': 1, 'False': 0, '': 0})\n",
        "\n",
        "# Ensure all columns are numeric for correlation calculation\n",
        "# Select only numeric columns\n",
        "numeric_df = repos_df.select_dtypes(include=['int', 'float'])\n",
        "\n",
        "# Create a Pearson correlation table for the numeric DataFrame\n",
        "correlation_matrix = numeric_df.corr(method='pearson')\n",
        "\n",
        "# Display the correlation matrix\n",
        "print(\"Pearson Correlation Matrix:\\n\", correlation_matrix)\n",
        "\n",
        "# Extract the correlation between 'has_projects' and 'has_wiki'\n",
        "correlation_projects_wiki = correlation_matrix.loc['has_projects', 'has_wiki']\n",
        "\n",
        "# Round the correlation to 3 decimal places\n",
        "correlation_projects_wiki_rounded = round(correlation_projects_wiki, 3)\n",
        "\n",
        "print(\"Correlation between projects enabled and wiki enabled:\", correlation_projects_wiki_rounded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMYHFBWLm0wR",
        "outputId": "ed4b89e2-3303-468d-a5d7-bc385aa079c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  login                 full_name            created_at  stargazers_count  \\\n",
            "0    tj  tj/node-cookie-signature  2012-10-15T15:54:33Z               185   \n",
            "1    tj           tj/commander.js  2011-08-14T21:33:58Z             26742   \n",
            "2    tj                      tj/n  2011-01-05T14:53:19Z             18863   \n",
            "3    tj             tj/git-extras  2010-08-04T16:32:07Z             17327   \n",
            "4    tj           tj/node-migrate  2011-04-24T21:00:22Z              1545   \n",
            "\n",
            "   watchers_count    language  has_projects  has_wiki license_name  \n",
            "0             185  JavaScript          True      True          mit  \n",
            "1           26742  JavaScript          True      True          mit  \n",
            "2           18863       Shell          True      True          mit  \n",
            "3           17327       Shell          True      True          mit  \n",
            "4            1545  JavaScript          True      True          mit  \n",
            "Pearson Correlation Matrix:\n",
            "                   stargazers_count  watchers_count  has_projects  has_wiki\n",
            "stargazers_count          1.000000        1.000000     -0.054977 -0.024280\n",
            "watchers_count            1.000000        1.000000     -0.054977 -0.024280\n",
            "has_projects             -0.054977       -0.054977      1.000000  0.446177\n",
            "has_wiki                 -0.024280       -0.024280      0.446177  1.000000\n",
            "Correlation between projects enabled and wiki enabled: 0.446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-138470ec52b9>:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  repos_df['has_projects'] = repos_df['has_projects'].replace({True: 1, False: 0, 'True': 1, 'False': 0, '': 0})\n",
            "<ipython-input-34-138470ec52b9>:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  repos_df['has_wiki'] = repos_df['has_wiki'].replace({True: 1, False: 0, 'True': 1, 'False': 0, '': 0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file\n",
        "repos_df = pd.read_csv('repositories.csv')  # Adjust the path if necessary\n",
        "\n",
        "# Check the first few rows to ensure it's loaded correctly\n",
        "print(repos_df.head())\n",
        "\n",
        "# Fill NaN values in 'has_projects' and 'has_wiki' columns with 0\n",
        "repos_df['has_projects'].fillna(0, inplace=True)\n",
        "repos_df['has_wiki'].fillna(0, inplace=True)\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to integers (1 for True, 0 for False)\n",
        "repos_df['has_projects'] = repos_df['has_projects'].replace({True: 1, False: 0, 'True': 1, 'False': 0, '': 0})\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].replace({True: 1, False: 0, 'True': 1, 'False': 0, '': 0})\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki\n",
        "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
        "\n",
        "# Round the correlation to 3 decimal places\n",
        "correlation_rounded = round(correlation, 3)\n",
        "\n",
        "print(\"Correlation between projects enabled and wiki enabled:\", correlation_rounded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbKobndjtNcH",
        "outputId": "fad6caf5-eed4-4f1c-bb61-933b1cdbb4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  login                 full_name            created_at  stargazers_count  \\\n",
            "0    tj  tj/node-cookie-signature  2012-10-15T15:54:33Z               185   \n",
            "1    tj           tj/commander.js  2011-08-14T21:33:58Z             26742   \n",
            "2    tj                      tj/n  2011-01-05T14:53:19Z             18863   \n",
            "3    tj             tj/git-extras  2010-08-04T16:32:07Z             17327   \n",
            "4    tj           tj/node-migrate  2011-04-24T21:00:22Z              1545   \n",
            "\n",
            "   watchers_count    language  has_projects  has_wiki license_name  \n",
            "0             185  JavaScript          True      True          mit  \n",
            "1           26742  JavaScript          True      True          mit  \n",
            "2           18863       Shell          True      True          mit  \n",
            "3           17327       Shell          True      True          mit  \n",
            "4            1545  JavaScript          True      True          mit  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-940c42566a0a>:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  repos_df['has_projects'].fillna(0, inplace=True)\n",
            "<ipython-input-35-940c42566a0a>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  repos_df['has_wiki'].fillna(0, inplace=True)\n",
            "<ipython-input-35-940c42566a0a>:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  repos_df['has_projects'] = repos_df['has_projects'].replace({True: 1, False: 0, 'True': 1, 'False': 0, '': 0})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between projects enabled and wiki enabled: 0.446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-940c42566a0a>:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  repos_df['has_wiki'] = repos_df['has_wiki'].replace({True: 1, False: 0, 'True': 1, 'False': 0, '': 0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file\n",
        "repos_df = pd.read_csv('repositories.csv')  # Adjust the path if necessary\n",
        "\n",
        "# Check the first few rows to ensure it's loaded correctly\n",
        "print(repos_df.head())\n",
        "\n",
        "# Fill NaN values in 'has_projects' and 'has_wiki' columns with 0\n",
        "repos_df['has_projects'] = repos_df['has_projects'].fillna(0)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].fillna(0)\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to integers (1 for True, 0 for False)\n",
        "repos_df['has_projects'] = repos_df['has_projects'].replace(\n",
        "    {True: 1, False: 0, 'True': 1, 'False': 0, '': 0}).astype(int)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].replace(\n",
        "    {True: 1, False: 0, 'True': 1, 'False': 0, '': 0}).astype(int)\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki\n",
        "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
        "\n",
        "# Round the correlation to 3 decimal places\n",
        "correlation_rounded = round(correlation, 3)\n",
        "\n",
        "print(\"Correlation between projects enabled and wiki enabled:\", correlation_rounded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBIr2yQjtbhi",
        "outputId": "dfccb867-4bb6-4c4a-9bb0-1439b0577931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  login                 full_name            created_at  stargazers_count  \\\n",
            "0    tj  tj/node-cookie-signature  2012-10-15T15:54:33Z               185   \n",
            "1    tj           tj/commander.js  2011-08-14T21:33:58Z             26742   \n",
            "2    tj                      tj/n  2011-01-05T14:53:19Z             18863   \n",
            "3    tj             tj/git-extras  2010-08-04T16:32:07Z             17327   \n",
            "4    tj           tj/node-migrate  2011-04-24T21:00:22Z              1545   \n",
            "\n",
            "   watchers_count    language  has_projects  has_wiki license_name  \n",
            "0             185  JavaScript          True      True          mit  \n",
            "1           26742  JavaScript          True      True          mit  \n",
            "2           18863       Shell          True      True          mit  \n",
            "3           17327       Shell          True      True          mit  \n",
            "4            1545  JavaScript          True      True          mit  \n",
            "Correlation between projects enabled and wiki enabled: 0.446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-91ac503a9195>:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  repos_df['has_projects'] = repos_df['has_projects'].replace(\n",
            "<ipython-input-36-91ac503a9195>:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  repos_df['has_wiki'] = repos_df['has_wiki'].replace(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file\n",
        "repos_df = pd.read_csv('repositories.csv')  # Adjust the path if necessary\n",
        "\n",
        "# Check the first few rows to ensure it's loaded correctly\n",
        "print(repos_df.head())\n",
        "\n",
        "# Fill blank values with 0 for has_projects and has_wiki\n",
        "repos_df['has_projects'].fillna(0, inplace=True)\n",
        "repos_df['has_wiki'].fillna(0, inplace=True)\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to integers (1 for true, 0 for false)\n",
        "repos_df['has_projects'] = repos_df['has_projects'].replace({true: 1, false: 0, 'true': 1, 'false': 0, '': 0})\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].replace({true: 1, false: 0, 'true': 1, 'false': 0, '': 0})\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki\n",
        "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
        "\n",
        "# Round the correlation to 3 decimal places\n",
        "correlation_rounded = round(correlation, 3)\n",
        "\n",
        "print(\"Correlation between projects enabled and wiki enabled:\", correlation_rounded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "2uQwneZTvl-A",
        "outputId": "18b5a32b-caf8-40d1-be09-3708be541623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  login                 full_name            created_at  stargazers_count  \\\n",
            "0    tj  tj/node-cookie-signature  2012-10-15T15:54:33Z               185   \n",
            "1    tj           tj/commander.js  2011-08-14T21:33:58Z             26742   \n",
            "2    tj                      tj/n  2011-01-05T14:53:19Z             18863   \n",
            "3    tj             tj/git-extras  2010-08-04T16:32:07Z             17327   \n",
            "4    tj           tj/node-migrate  2011-04-24T21:00:22Z              1545   \n",
            "\n",
            "   watchers_count    language  has_projects  has_wiki license_name  \n",
            "0             185  JavaScript          True      True          mit  \n",
            "1           26742  JavaScript          True      True          mit  \n",
            "2           18863       Shell          True      True          mit  \n",
            "3           17327       Shell          True      True          mit  \n",
            "4            1545  JavaScript          True      True          mit  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-9cf5d012d665>:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  repos_df['has_projects'].fillna(0, inplace=True)\n",
            "<ipython-input-37-9cf5d012d665>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  repos_df['has_wiki'].fillna(0, inplace=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'true' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-9cf5d012d665>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Convert 'has_projects' and 'has_wiki' to integers (1 for true, 0 for false)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_projects'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_projects'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'false'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_wiki'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_wiki'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'false'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'true' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file\n",
        "repos_df = pd.read_csv('repositories.csv')  # Adjust the path if necessary\n",
        "\n",
        "# Fill NaN values with empty strings for 'has_projects' and 'has_wiki'\n",
        "repos_df['has_projects'].fillna('', inplace=True)\n",
        "repos_df['has_wiki'].fillna('', inplace=True)\n",
        "\n",
        "# Replace boolean values with 'true', 'false', and empty strings\n",
        "repos_df['has_projects'] = repos_df['has_projects'].replace({True: 'true', False: 'false', 'True': 'true', 'False': 'false', '': 'false'})\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].replace({True: 'true', False: 'false', 'True': 'true', 'False': 'false', '': 'false'})\n",
        "\n",
        "# Convert to integer (1 for true, 0 for false)\n",
        "repos_df['has_projects'] = repos_df['has_projects'].map({'true': 1, 'false': 0})\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].map({'true': 1, 'false': 0})\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki\n",
        "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
        "\n",
        "# Round the correlation to 3 decimal places\n",
        "correlation_rounded = round(correlation, 3)\n",
        "\n",
        "print(\"Correlation between projects enabled and wiki enabled:\", correlation_rounded)\n"
      ],
      "metadata": {
        "id": "-Sm6kmZbwBJs",
        "outputId": "46187952-ffc0-4ea5-c85f-2845c1ab8928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between projects enabled and wiki enabled: 0.446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-93c23324796a>:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  repos_df['has_projects'].fillna('', inplace=True)\n",
            "<ipython-input-38-93c23324796a>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  repos_df['has_wiki'].fillna('', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the users.csv file (make sure the path is correct)\n",
        "users_df = pd.read_csv('users.csv')  # Update with your actual path\n",
        "\n",
        "# Filter out users without bios\n",
        "filtered_df = users_df[users_df['bio'].notna()]\n",
        "\n",
        "# Calculate the length of each bio in terms of word count\n",
        "filtered_df['bio_word_count'] = filtered_df['bio'].str.split().str.len()\n",
        "\n",
        "# Prepare the data for regression (only include relevant columns)\n",
        "X = filtered_df['bio_word_count']\n",
        "y = filtered_df['followers']\n",
        "\n",
        "# Add a constant to the independent variable for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the slope (coefficient) for bio word count\n",
        "slope = model.params['bio_word_count']\n",
        "\n",
        "# Round the slope to 3 decimal places\n",
        "slope_rounded = round(slope, 3)\n",
        "\n",
        "print(\"Regression slope of followers on bio word count:\", slope_rounded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDM3ixHJY4Xn",
        "outputId": "95cc7877-58c0-47d9-deeb-4375dcaca9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression slope of followers on bio word count: 1.995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-5be1e62ac177>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['bio_word_count'] = filtered_df['bio'].str.split().str.len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file\n",
        "repos_df = pd.read_csv('repositories.csv')  # Update the path as necessary\n",
        "\n",
        "# Convert the created_at column to datetime\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
        "\n",
        "# Filter for weekend entries (Saturday: 5, Sunday: 6)\n",
        "repos_df['day_of_week'] = repos_df['created_at'].dt.dayofweek\n",
        "weekend_repos_df = repos_df[(repos_df['day_of_week'] == 5) | (repos_df['day_of_week'] == 6)]\n",
        "\n",
        "# Group by login and count the number of repositories created\n",
        "user_repo_counts = weekend_repos_df.groupby('login').size().reset_index(name='repo_count')\n",
        "\n",
        "# Sort by repo_count in descending order and get the top 5\n",
        "top_users = user_repo_counts.sort_values(by='repo_count', ascending=False).head(5)\n",
        "\n",
        "# Get the list of top 5 users' logins in order, comma-separated\n",
        "top_users_logins = ', '.join(top_users['login'])\n",
        "\n",
        "print(\"Top 5 users who created the most repositories on weekends (UTC):\", top_users_logins)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPK5IbhCZOvp",
        "outputId": "6872293e-3409-4199-b70c-f4420eae8991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users who created the most repositories on weekends (UTC): praveenscience, mattdesl, passy, CodeMaster7000, UKVeteran\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users.csv file (update the path if needed)\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Filter for hireable users and calculate fraction with email\n",
        "hireable_users = users_df[users_df['hireable'] == True]\n",
        "fraction_hireable_with_email = hireable_users['email'].notna().mean()\n",
        "\n",
        "# Filter for non-hireable users and calculate fraction with email\n",
        "non_hireable_users = users_df[users_df['hireable'] == False]\n",
        "fraction_non_hireable_with_email = non_hireable_users['email'].notna().mean()\n",
        "\n",
        "# Calculate the difference, rounded to 3 decimal places\n",
        "difference = round(fraction_hireable_with_email - fraction_non_hireable_with_email, 3)\n",
        "\n",
        "print(\"Difference in email sharing between hireable and non-hireable users:\", difference)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_3WRDaCZjHQ",
        "outputId": "23c656bc-28b9-4926-891c-93968461fc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in email sharing between hireable and non-hireable users: 0.061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users.csv file (adjust the path if needed)\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Filter out rows with missing names\n",
        "users_with_names = users_df[users_df['name'].notna()]\n",
        "\n",
        "# Extract surnames (last word in the name column after trimming)\n",
        "users_with_names['surname'] = users_with_names['name'].str.strip().str.split().str[-1]\n",
        "\n",
        "# Count occurrences of each surname\n",
        "surname_counts = users_with_names['surname'].value_counts()\n",
        "\n",
        "# Find the maximum count\n",
        "max_count = surname_counts.max()\n",
        "\n",
        "# Get all surnames with the maximum count, sort them alphabetically\n",
        "most_common_surnames = surname_counts[surname_counts == max_count].index.sort_values()\n",
        "\n",
        "# Join them into a comma-separated string\n",
        "most_common_surnames_list = ', '.join(most_common_surnames)\n",
        "\n",
        "print(\"Most common surname(s):\", most_common_surnames_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OasOsc6oZwVS",
        "outputId": "75de4668-e184-42b5-cd9a-ad678b9c0f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common surname(s): Appleton, Brewery, Fuller, Greenfeld, Jackson, Li, Williams\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-4ee50563d6c1>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  users_with_names['surname'] = users_with_names['name'].str.strip().str.split().str[-1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users.csv file (adjust the path if needed)\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Filter out rows with missing names\n",
        "users_with_names = users_df[users_df['name'].notna()]\n",
        "\n",
        "# Extract surnames (last word in the name column after trimming)\n",
        "users_with_names['surname'] = users_with_names['name'].str.strip().str.split().str[-1]\n",
        "\n",
        "# Count occurrences of each surname\n",
        "surname_counts = users_with_names['surname'].value_counts()\n",
        "\n",
        "# Find the maximum count\n",
        "max_count = surname_counts.max()\n",
        "\n",
        "# Get all surnames with the maximum count, sort them alphabetically\n",
        "most_common_surnames = surname_counts[surname_counts == max_count].index.sort_values()\n",
        "\n",
        "# Join them into a comma-separated string\n",
        "most_common_surnames_list = ', '.join(most_common_surnames)\n",
        "\n",
        "print(\"Most common surname(s):\", most_common_surnames_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhXn7lXjaJTn",
        "outputId": "22bad02b-5a28-411e-d21e-7ed902f01c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common surname(s): Appleton, Brewery, Fuller, Greenfeld, Jackson, Li, Williams\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-4ee50563d6c1>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  users_with_names['surname'] = users_with_names['name'].str.strip().str.split().str[-1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users.csv file (adjust the path if needed)\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate the average following count for hireable users\n",
        "hireable_avg_following = users_df[users_df['hireable'] == True]['following'].mean()\n",
        "\n",
        "# Calculate the average following count for non-hireable users\n",
        "non_hireable_avg_following = users_df[users_df['hireable'] == False]['following'].mean()\n",
        "\n",
        "# Calculate the difference, rounded to 3 decimal places\n",
        "difference = round(hireable_avg_following - non_hireable_avg_following, 3)\n",
        "\n",
        "print(\"Difference in average following between hireable and non-hireable users:\", difference)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B8dpVXRaOVO",
        "outputId": "1c004c2f-e230-4c53-d4be-8f32fec577f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in average following between hireable and non-hireable users: 1082.745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file (adjust the path if necessary)\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki, rounded to 3 decimal places\n",
        "correlation = round(repos_df['has_wiki'].astype(int).corr(repos_df['has_projects'].astype(int)), 3)\n",
        "\n",
        "print(\"Correlation between projects and wiki enabled:\", correlation)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivstdInJbUz3",
        "outputId": "d5a879bb-c2fa-4d42-ec01-2e734ac41e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between projects and wiki enabled: 0.446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file (adjust the path if necessary)\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Clean the has_projects and has_wiki columns by removing spaces and converting to booleans\n",
        "repos_df['has_projects'] = repos_df['has_projects'].str.strip().map(lambda x: x == \"True\")\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].str.strip().map(lambda x: x == \"True\")\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki, rounded to 3 decimal places\n",
        "correlation = round(repos_df['has_projects'].astype(int).corr(repos_df['has_wiki'].astype(int)), 3)\n",
        "\n",
        "print(\"Correlation between projects and wiki enabled:\", correlation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "AQFGEbwYeVtT",
        "outputId": "14da8d44-6754-4f0f-b766-40b900f26a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Can only use .str accessor with string values!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c235f34bb3d4>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Clean the has_projects and has_wiki columns by removing spaces and converting to booleans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_projects'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_projects'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_wiki'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_wiki'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file (adjust the path if necessary)\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Ensure the columns are strings, then strip spaces and convert to booleans\n",
        "repos_df['has_projects'] = repos_df['has_projects'].astype(str).str.strip().map(lambda x: x == \"True\")\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].astype(str).str.strip().map(lambda x: x == \"True\")\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki, rounded to 3 decimal places\n",
        "correlation = round(repos_df['has_projects'].astype(int).corr(repos_df['has_wiki'].astype(int)), 3)\n",
        "\n",
        "print(\"Correlation between projects and wiki enabled:\", correlation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml2ubLeael-l",
        "outputId": "bda5a019-3182-4b2c-cd04-76b089a3f832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between projects and wiki enabled: 0.446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file (adjust the path if necessary)\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Define a function to clean and convert the values to booleans, treating blanks as False\n",
        "def clean_boolean(value):\n",
        "    # Check for NaN or empty strings and return False for them\n",
        "    if pd.isna(value) or str(value).strip() == \"\":\n",
        "        return False\n",
        "    # Otherwise, return True if the cleaned value is exactly \"True\"\n",
        "    return str(value).strip() == \"True\"\n",
        "\n",
        "# Apply the cleaning function to has_projects and has_wiki columns\n",
        "repos_df['has_projects'] = repos_df['has_projects'].apply(clean_boolean)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].apply(clean_boolean)\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki, rounded to 3 decimal places\n",
        "correlation = round(repos_df['has_projects'].astype(int).corr(repos_df['has_wiki'].astype(int)), 3)\n",
        "\n",
        "print(\"Correlation between projects and wiki enabled:\", correlation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWm4jCnRfPaF",
        "outputId": "4bb03773-35af-41f3-b034-049992f91f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between projects and wiki enabled: 0.446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file (adjust the path if necessary)\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Define a function to clean and convert the values to booleans, treating blanks as False\n",
        "def clean_boolean(value):\n",
        "    # Treat blanks or NaNs as False\n",
        "    return str(value).strip() == \"True\" if pd.notna(value) and str(value).strip() != \"\" else False\n",
        "\n",
        "# Apply the cleaning function to has_projects and has_wiki columns\n",
        "repos_df['has_projects'] = repos_df['has_projects'].apply(clean_boolean)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].apply(clean_boolean)\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki, rounded to 3 decimal places\n",
        "correlation = round(repos_df['has_projects'].astype(int).corr(repos_df['has_wiki'].astype(int)), 3)\n",
        "\n",
        "print(\"Correlation between projects and wiki enabled:\", correlation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JASPWrwgfkfp",
        "outputId": "e5a52213-d5dd-48cf-b9e3-8f8af695683b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between projects and wiki enabled: 0.446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file (adjust the path if necessary)\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Define a function to clean and convert the values to booleans, treating blanks as False\n",
        "def clean_boolean(value):\n",
        "    # Treat blanks or NaNs as False\n",
        "    return str(value).strip() == \"True\" if pd.notna(value) and str(value).strip() != \"\" else False\n",
        "\n",
        "# Apply the cleaning function to has_projects and has_wiki columns\n",
        "repos_df['has_projects'] = repos_df['has_projects'].apply(clean_boolean)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].apply(clean_boolean)\n",
        "\n",
        "# Check if there's enough variability in data before calculating correlation\n",
        "if repos_df['has_projects'].nunique() > 1 and repos_df['has_wiki'].nunique() > 1:\n",
        "    # Calculate the correlation if there's variability\n",
        "    correlation = round(repos_df['has_projects'].astype(int).corr(repos_df['has_wiki'].astype(int)), 3)\n",
        "else:\n",
        "    # Set correlation to None or a specific message if no variability\n",
        "    correlation = \"Not enough variability in data to calculate correlation\"\n",
        "\n",
        "print(\"Correlation between projects and wiki enabled:\", correlation)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQi8aA5MgbdX",
        "outputId": "b6e38da8-7c09-494b-8039-9c90b160b29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between projects and wiki enabled: 0.446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "url = 'https://raw.githubusercontent.com/azh-py/london-github-users/refs/heads/main/repositories.csv'\n",
        "repos_df = pd.read_csv(url)\n",
        "\n",
        "# Clean the has_projects and has_wiki columns\n",
        "repos_df['has_projects'] = repos_df['has_projects'].str.strip().map(lambda x: x == \"True\")  # Convert to boolean\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].str.strip().map(lambda x: x == \"True\")  # Convert to boolean\n",
        "\n",
        "# Treat NaN as False\n",
        "repos_df['has_projects'] = repos_df['has_projects'].fillna(False)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].fillna(False)\n",
        "\n",
        "# Calculate correlation\n",
        "correlation = repos_df['has_projects'].astype(int).corr(repos_df['has_wiki'].astype(int))\n",
        "print(f'Correlation between has_projects and has_wiki: {correlation:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "ox8Z3fZHjt76",
        "outputId": "5b07c822-abda-4b2d-fc3f-83c0fe6ae2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Can only use .str accessor with string values!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-58cbaa69c368>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Clean the has_projects and has_wiki columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_projects'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_projects'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"True\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to boolean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_wiki'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_wiki'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"True\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to boolean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is already loaded in a variable named repos_df\n",
        "# If not, load it from the file like this:\n",
        "# repos_df = pd.read_csv('path_to_your/repositories.csv')\n",
        "\n",
        "# Fill blank (NaN) values in a specific column with 0\n",
        "# Replace 'column_name' with the actual name of the column you want to fill\n",
        "repos_df['column_name'] = repos_df['column_name'].fillna(0)\n",
        "\n",
        "# Example: Fill NaN in the 'stargazers_count' column with 0\n",
        "repos_df['stargazers_count'] = repos_df['stargazers_count'].fillna(0)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "repos_df.head()  # Show the first few rows to verify changes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "GWK206mBmK_x",
        "outputId": "caf150cc-fc96-42f8-a723-f97f00fcdc1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'column_name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'column_name'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b2faa6544cea>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fill blank (NaN) values in a specific column with 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Replace 'column_name' with the actual name of the column you want to fill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'column_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'column_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Example: Fill NaN in the 'stargazers_count' column with 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'column_name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users.csv file from the GitHub repository\n",
        "url = 'https://raw.githubusercontent.com/azh-py/london-github-users/main/users.csv'\n",
        "users_df = pd.read_csv(url)\n",
        "\n",
        "# Calculate leader_strength\n",
        "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
        "\n",
        "# Get the top 5 users based on leader_strength\n",
        "top_leaders = users_df.nlargest(5, 'leader_strength')['login']\n",
        "\n",
        "# Convert the top leaders to a comma-separated string\n",
        "top_leaders_list = ', '.join(top_leaders)\n",
        "top_leaders_list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "x3NElLTOWVga",
        "outputId": "a3615121-1da7-4257-a0b1-b63b0989ec56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'kunal-kushwaha, angelabauer, Elfocrash, LaravelDaily, cloudflare'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users.csv file from the GitHub repository\n",
        "url = 'https://raw.githubusercontent.com/azh-py/london-github-users/main/users.csv'\n",
        "users_df = pd.read_csv(url)\n",
        "\n",
        "# Let's assume the users_df contains columns for 'projects_enabled' and 'wiki_enabled'\n",
        "# Since we don't have this data directly, we'll create a mock DataFrame with the required structure.\n",
        "\n",
        "# Sample Data (replace this with actual data if available)\n",
        "data = {\n",
        "    'repo_name': ['repo1', 'repo2', 'repo3', 'repo4', 'repo5', 'repo6'],\n",
        "    'projects_enabled': [1, 1, 0, 1, 0, 0],  # 1 for enabled, 0 for disabled\n",
        "    'wiki_enabled': [1, 0, 0, 1, 1, 0]  # 1 for enabled, 0 for disabled\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "repos_df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the correlation between projects_enabled and wiki_enabled\n",
        "correlation = repos_df['projects_enabled'].corr(repos_df['wiki_enabled'])\n",
        "\n",
        "# Round to 3 decimal places\n",
        "correlation_rounded = round(correlation, 3)\n",
        "correlation_rounded\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkBgJPOCWpV8",
        "outputId": "1ffe689e-d072-4bad-edd6-584daddee044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.333"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# GitHub API settings\n",
        "GITHUB_TOKEN = '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'  # Replace with your actual token\n",
        "headers = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
        "base_url = \"https://api.github.com\"\n",
        "\n",
        "# Function to clean the company names\n",
        "def clean_company_name(company):\n",
        "    if company:\n",
        "        company = company.strip()  # Trim whitespace\n",
        "        if company.startswith('@'):\n",
        "            company = company[1:]  # Strip leading @ symbol\n",
        "        return company.upper()  # Convert to uppercase\n",
        "    return company\n",
        "\n",
        "# Function to fetch users in London with over 500 followers\n",
        "def get_users(city=\"London\", min_followers=500, max_results=100):\n",
        "    users_data = []\n",
        "    page = 1\n",
        "    while len(users_data) < max_results:\n",
        "        users_url = f\"{base_url}/search/users?q=location:{city}+followers:>{min_followers}&page={page}&per_page=30\"\n",
        "        response = requests.get(users_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        users = response.json().get('items', [])\n",
        "\n",
        "        if not users:  # Stop if there are no more users\n",
        "            break\n",
        "\n",
        "        for user in users:\n",
        "            user_detail_url = user['url']\n",
        "            user_detail_response = requests.get(user_detail_url, headers=headers)\n",
        "            user_detail_response.raise_for_status()\n",
        "            user_detail = user_detail_response.json()\n",
        "\n",
        "            users_data.append({\n",
        "                \"login\": user['login'],\n",
        "                \"name\": user_detail.get('name', ''),\n",
        "                \"company\": clean_company_name(user_detail.get('company')),\n",
        "                \"location\": user_detail.get('location', ''),\n",
        "                \"email\": user_detail.get('email', ''),\n",
        "                \"hireable\": user_detail.get('hireable', ''),\n",
        "                \"bio\": user_detail.get('bio', ''),\n",
        "                \"public_repos\": user_detail.get('public_repos', 0),\n",
        "                \"followers\": user_detail.get('followers', 0),\n",
        "                \"following\": user_detail.get('following', 0),\n",
        "                \"created_at\": user_detail.get('created_at', ''),\n",
        "            })\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)  # Sleep to respect API rate limits\n",
        "\n",
        "    return users_data\n",
        "\n",
        "# Function to fetch repositories for a given user\n",
        "def get_repositories(user_login, max_results=500):\n",
        "    repos_data = []\n",
        "    page = 1\n",
        "\n",
        "    while len(repos_data) < max_results:\n",
        "        repos_url = f\"{base_url}/users/{user_login}/repos?sort=pushed&direction=desc&page={page}&per_page=100\"\n",
        "        response = requests.get(repos_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        repos = response.json()\n",
        "\n",
        "        if not repos:  # Stop if there are no more repositories\n",
        "            break\n",
        "\n",
        "        for repo in repos:\n",
        "            repos_data.append({\n",
        "                \"login\": user_login,\n",
        "                \"full_name\": repo['full_name'],\n",
        "                \"created_at\": repo['created_at'],\n",
        "                \"stargazers_count\": repo['stargazers_count'],\n",
        "                \"watchers_count\": repo['watchers_count'],\n",
        "                \"language\": repo['language'],\n",
        "                \"has_projects\": repo['has_projects'],\n",
        "                \"has_wiki\": repo['has_wiki'],\n",
        "                \"license_name\": repo['license']['name'] if repo['license'] else None,\n",
        "            })\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)  # Sleep to respect API rate limits\n",
        "\n",
        "    return repos_data\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    users = get_users()\n",
        "    print(f\"Found {len(users)} users with over 500 followers in London.\")\n",
        "\n",
        "    # Save user details to a CSV file\n",
        "    users_df = pd.DataFrame(users)\n",
        "    users_df.to_csv('users.csv', index=False)\n",
        "\n",
        "    # Fetch repositories for each user and save to repositories.csv\n",
        "    all_repos_data = []\n",
        "    for user in users:\n",
        "        print(f\"Fetching repositories for {user['login']}...\")\n",
        "        repos = get_repositories(user['login'])\n",
        "        all_repos_data.extend(repos)\n",
        "\n",
        "    repos_df = pd.DataFrame(all_repos_data)\n",
        "    repos_df.to_csv('repositories.csv', index=False)\n",
        "\n",
        "\n",
        "def print_repositories():\n",
        "    repos_df = pd.read_csv('repositories.csv')\n",
        "    print(repos_df)\n",
        "\n",
        "# Call the function to print repositories after fetching\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    print_repositories()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ-TbESDDMf1",
        "outputId": "92f0ab1c-2e05-48fb-8f53-45363afd1e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 120 users with over 500 followers in London.\n",
            "Fetching repositories for tj...\n",
            "Fetching repositories for kunal-kushwaha...\n",
            "Fetching repositories for angelabauer...\n",
            "Fetching repositories for jlord...\n",
            "Fetching repositories for Elfocrash...\n",
            "Fetching repositories for alyssaxuu...\n",
            "Fetching repositories for eddiejaoude...\n",
            "Fetching repositories for daneden...\n",
            "Fetching repositories for LaravelDaily...\n",
            "Fetching repositories for jskeet...\n",
            "Fetching repositories for mattdesl...\n",
            "Fetching repositories for cloudflare...\n",
            "Fetching repositories for nicklockwood...\n",
            "Fetching repositories for jgthms...\n",
            "Fetching repositories for bizz84...\n",
            "Fetching repositories for samuelcolvin...\n",
            "Fetching repositories for Lissy93...\n",
            "Fetching repositories for jgilfelt...\n",
            "Fetching repositories for sonnysangha...\n",
            "Fetching repositories for nickbutcher...\n",
            "Fetching repositories for florina-muntenescu...\n",
            "Fetching repositories for pydanny...\n",
            "Fetching repositories for SaraVieira...\n",
            "Fetching repositories for dsyer...\n",
            "Fetching repositories for trueadm...\n",
            "Fetching repositories for matryer...\n",
            "Fetching repositories for adamchainz...\n",
            "Fetching repositories for gordicaleksa...\n",
            "Fetching repositories for lewagon...\n",
            "Fetching repositories for threepointone...\n",
            "Fetching repositories for lizrice...\n",
            "Fetching repositories for Soldy...\n",
            "Fetching repositories for londonappbrewery...\n",
            "Fetching repositories for jasondavies...\n",
            "Fetching repositories for sdiehl...\n",
            "Fetching repositories for ArefMq...\n",
            "Fetching repositories for steveruizok...\n",
            "Fetching repositories for Archakov06...\n",
            "Fetching repositories for mlabonne...\n",
            "Fetching repositories for appbrewery...\n",
            "Fetching repositories for jspahrsummers...\n",
            "Fetching repositories for emilsjolander...\n",
            "Fetching repositories for dli...\n",
            "Fetching repositories for lucasr...\n",
            "Fetching repositories for TryCatchLearn...\n",
            "Fetching repositories for riggaroo...\n",
            "Fetching repositories for paullewis...\n",
            "Fetching repositories for soulwire...\n",
            "Fetching repositories for spite...\n",
            "Fetching repositories for MachineLearnia...\n",
            "Fetching repositories for gajus...\n",
            "Fetching repositories for mvdan...\n",
            "Fetching repositories for 0atman...\n",
            "Fetching repositories for kylef...\n",
            "Fetching repositories for passy...\n",
            "Fetching repositories for laurent22...\n",
            "Fetching repositories for canonical...\n",
            "Fetching repositories for slightfoot...\n",
            "Fetching repositories for VagrantStory...\n",
            "Fetching repositories for lpil...\n",
            "Fetching repositories for praveenscience...\n",
            "Fetching repositories for christiannwamba...\n",
            "Fetching repositories for audreyfeldroy...\n",
            "Fetching repositories for PaulKinlan...\n",
            "Fetching repositories for atherosai...\n",
            "Fetching repositories for cortinico...\n",
            "Fetching repositories for fabiospampinato...\n",
            "Fetching repositories for fluttercommunity...\n",
            "Fetching repositories for robmarkcole...\n",
            "Fetching repositories for TodePond...\n",
            "Fetching repositories for nicholasjackson...\n",
            "Fetching repositories for weavejester...\n",
            "Fetching repositories for kitten...\n",
            "Fetching repositories for MaggieAppleton...\n",
            "Fetching repositories for HariSekhon...\n",
            "Fetching repositories for paritytech...\n",
            "Fetching repositories for ohld...\n",
            "Fetching repositories for Patalin...\n",
            "Fetching repositories for derickr...\n",
            "Fetching repositories for ItzLevvie...\n",
            "Fetching repositories for serengil...\n",
            "Fetching repositories for BYK...\n",
            "Fetching repositories for bee-san...\n",
            "Fetching repositories for keithamus...\n",
            "Fetching repositories for ForbesLindesay...\n",
            "Fetching repositories for lovell...\n",
            "Fetching repositories for sergiecode...\n",
            "Fetching repositories for petebacondarwin...\n",
            "Fetching repositories for jacobbinnie...\n",
            "Fetching repositories for sebastianstarke...\n",
            "Fetching repositories for ualehosaini...\n",
            "Fetching repositories for kadikraman...\n",
            "Fetching repositories for umaar...\n",
            "Fetching repositories for jcoglan...\n",
            "Fetching repositories for mikedewar...\n",
            "Fetching repositories for albinotonnina...\n",
            "Fetching repositories for peter-lawrey...\n",
            "Fetching repositories for samdutton...\n",
            "Fetching repositories for a7v8x...\n",
            "Fetching repositories for nelstrom...\n",
            "Fetching repositories for postspectacular...\n",
            "Fetching repositories for dylanbeattie...\n",
            "Fetching repositories for jackfranklin...\n",
            "Fetching repositories for Lukasa...\n",
            "Fetching repositories for bashtage...\n",
            "Fetching repositories for benjojo...\n",
            "Fetching repositories for bookercodes...\n",
            "Fetching repositories for kelset...\n",
            "Fetching repositories for OlafenwaMoses...\n",
            "Fetching repositories for arkivanov...\n",
            "Fetching repositories for abreslav...\n",
            "Fetching repositories for MicheleBertoli...\n",
            "Fetching repositories for jevakallio...\n",
            "Fetching repositories for MattIPv4...\n",
            "Fetching repositories for jakewright...\n",
            "Fetching repositories for RichardWarburton...\n",
            "Fetching repositories for benanne...\n",
            "Fetching repositories for sixeyed...\n",
            "Fetching repositories for snyk...\n",
            "Fetching repositories for FranxYao...\n",
            "          login                          full_name            created_at  \\\n",
            "0            tj           tj/node-cookie-signature  2012-10-15T15:54:33Z   \n",
            "1            tj                    tj/commander.js  2011-08-14T21:33:58Z   \n",
            "2            tj                               tj/n  2011-01-05T14:53:19Z   \n",
            "3            tj                      tj/git-extras  2010-08-04T16:32:07Z   \n",
            "4            tj                    tj/node-migrate  2011-04-24T21:00:22Z   \n",
            "...         ...                                ...                   ...   \n",
            "17732  FranxYao                    FranxYao/models  2017-06-25T16:38:26Z   \n",
            "17733  FranxYao                  FranxYao/STRAIGHT  2017-03-04T06:27:53Z   \n",
            "17734  FranxYao  FranxYao/a-simple-riscv-simulator  2016-11-10T14:46:36Z   \n",
            "17735  FranxYao                     FranxYao/keras  2016-11-08T13:01:01Z   \n",
            "17736  FranxYao                FranxYao/tensorflow  2016-07-16T13:53:58Z   \n",
            "\n",
            "       stargazers_count  watchers_count    language  has_projects  has_wiki  \\\n",
            "0                   185             185  JavaScript          True      True   \n",
            "1                 26739           26739  JavaScript          True      True   \n",
            "2                 18861           18861       Shell          True      True   \n",
            "3                 17325           17325       Shell          True      True   \n",
            "4                  1545            1545  JavaScript          True      True   \n",
            "...                 ...             ...         ...           ...       ...   \n",
            "17732                 0               0      Python          True      True   \n",
            "17733                 0               0      Matlab          True      True   \n",
            "17734                 0               0         C++          True      True   \n",
            "17735                 0               0      Python          True      True   \n",
            "17736                 0               0         C++          True     False   \n",
            "\n",
            "             license_name  \n",
            "0             MIT License  \n",
            "1             MIT License  \n",
            "2             MIT License  \n",
            "3             MIT License  \n",
            "4             MIT License  \n",
            "...                   ...  \n",
            "17732  Apache License 2.0  \n",
            "17733                 NaN  \n",
            "17734                 NaN  \n",
            "17735               Other  \n",
            "17736  Apache License 2.0  \n",
            "\n",
            "[17737 rows x 9 columns]\n"
          ]
        }
      ]
    }
  ]
}